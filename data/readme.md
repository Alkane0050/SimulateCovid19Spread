# ReadMe

## 爬虫说明

所有数据都是从[百度迁徙](https://qianxi.baidu.com/)中抓取,本人对数据的真实性不负责任。

## 脚本

### getMmatrix.py

在`cityAndId.json`中填写需要的城市与id

如下格式:

```json
{
    "武汉市": 420100,
    "黄冈市": 421100,
    "孝感市": 420900,
    ...
}
```

其中每个城市对应的id为其相应的行政区号,城市的名字以[百度迁徙](https://qianxi.baidu.com/)中的为准,一般为`城市名+市`,部分少数民族自治区等名称特殊的城市需要去[百度迁徙](https://qianxi.baidu.com/)中核实。



### getFactor.py

与`getMmatrix.py`类似

## 数据



已经按照下列顺序，将迁出城市的数据与该城市的迁徙指数做成了csv文件

|    City    |
| :--------: |
|    武汉    |
|    黄冈    |
|    孝感    |
|    襄阳    |
|    随州    |
|    荆门    |
|    荆州    |
|    鄂州    |
|    黄石    |
|    宜昌    |
|    咸宁    |
|    十堰    |
|    仙桃    |
|   恩施州   |
|    天门    |
|    潜江    |
| 神农架林区 |
|    温州    |
|    杭州    |
|    台州    |
|    宁波    |
|    深圳    |
|    广州    |
|    佛山    |
|    南阳    |
|    郑州    |
|    信阳    |
|    周口    |
|   驻马店   |
|    长沙    |
|    岳阳    |
|    常德    |
|    邵阳    |
|    南昌    |
|    九江    |
|    合肥    |
|    阜阳    |
|    重庆    |
|    成都    |
|    苏州    |
|    南京    |
|    上海    |
|    北京    |
|    福州    |
|    西安    |
|    天津    |



### M2020xxxx.csv

按照xxxx的日期,第$i,j$行对应上表中第$i$个城市当天迁出到第$j$个城市的比例。

由于百度上只能爬到迁出比例为前50的数据，若$M_{i,j}$ 为0,就表示数据无法获取，但是考虑到不在前50中，可以用0来近似处理。



### Factor_in/out.csv

第$i$行对应上表中的第$i$个城市,第$j$列为从2020/01/01 至 2020/01/30 中的第$j$天当天的迁徙规模。

不同城市之前可以用这个值进行比较



### dicOfMatrix.pickle

我把原始数据存在该文件中,该文件为字典型的数据

可以按照如下的步骤提取数据

```python
import pickle
with open("dicOfMatrix.pickle",'rb') as f:
    data = pickle.load(f)
```



其中`data`为字典型的数据,key为`int`型，如：

```python
data[20200101] 
```

会得到一个`46x46`的`ndarray`